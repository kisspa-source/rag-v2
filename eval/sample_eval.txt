RAG (Retrieval-Augmented Generation)는 대규모 언어 모델(LLM)의 출력을 최적화하여 응답의 정확도와 신뢰성을 높이는 기술입니다.

RAG의 주요 장점:
1. 최신 정보 반영: LLM은 학습 데이터에 포함되지 않은 최신 정보를 검색하여 답변할 수 있습니다.
2. 환각(Hallucination) 감소: 근거 문서를 기반으로 답변하므로 거짓 정보를 생성할 가능성이 줄어듭니다.
3. 출처 제공: 답변의 근거가 되는 문서와 페이지를 명시하여 신뢰성을 높일 수 있습니다.
4. 보안성: 민감한 데이터를 LLM 학습에 사용하지 않고, 로컬 검색을 통해 안전하게 활용할 수 있습니다.

RAG 시스템의 구성 요소:
- Document Loader: 다양한 형식의 문서를 텍스트로 변환합니다.
- Text Splitter: 긴 텍스트를 작은 청크(Chunk)로 나눕니다.
- Embedding Model: 텍스트를 벡터로 변환합니다.
- Vector Database: 벡터를 저장하고 유사도 검색을 수행합니다.
- Retriever: 질문과 관련된 문서를 검색합니다.
- LLM: 검색된 문서를 바탕으로 답변을 생성합니다.

RAG 성능 최적화 기법:
- Hybrid Search: 키워드 검색(BM25)과 벡터 검색을 결합하여 정확도를 높입니다.
- Rerank: 검색된 결과의 순위를 재조정하여 가장 관련성 높은 문서를 상위에 배치합니다.
- Query Expansion: 질문을 확장하거나 재구성하여 검색 범위를 넓힙니다.
- Metadata Filtering: 날짜, 작성자 등 메타데이터를 활용하여 검색 범위를 좁힙니다.
